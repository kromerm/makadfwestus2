{
	"name": "metadataChecker",
	"properties": {
		"description": "Sample metadata checker rules",
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"dataset": {
						"referenceName": "genericfolder",
						"type": "DatasetReference"
					},
					"name": "source1"
				},
				{
					"dataset": {
						"referenceName": "SQLProducts_new",
						"type": "DatasetReference"
					},
					"name": "DBSource"
				}
			],
			"sinks": [
				{
					"dataset": {
						"referenceName": "folderout1",
						"type": "DatasetReference"
					},
					"name": "WriteResults"
				},
				{
					"name": "OutputToPipeline"
				}
			],
			"transformations": [
				{
					"name": "ConditionalSplit1"
				},
				{
					"name": "ColumnCount"
				},
				{
					"name": "BuildModel"
				},
				{
					"name": "GroupBadSources"
				},
				{
					"name": "GroupGoodSources"
				},
				{
					"name": "LabelSource"
				},
				{
					"name": "LabelSource2"
				},
				{
					"name": "SetAsBad"
				},
				{
					"name": "SetAsGood"
				},
				{
					"name": "GroupAll"
				},
				{
					"name": "CountBadGood"
				}
			],
			"script": "parameters{\n\tfilename as string ('SampleData/moviesDB.csv'),\n\tcolumns as string ('movie,title'),\n\tdbname as string ('products')\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tlimit: 1,\n\tignoreNoFilesFound: false,\n\twildcardPaths:[($filename)]) ~> source1\nsource(output(\n\t\tProductID as integer,\n\t\tName as string,\n\t\tProductNumber as string,\n\t\tColor as string,\n\t\tStandardCost as decimal(19,4),\n\t\tListPrice as decimal(19,4),\n\t\tSize as string,\n\t\tWeight as decimal(8,2),\n\t\tProductCategoryID as integer,\n\t\tProductModelID as integer,\n\t\tSellStartDate as timestamp,\n\t\tSellEndDate as timestamp,\n\t\tDiscontinuedDate as timestamp,\n\t\tThumbnailPhotoFileName as string,\n\t\trowguid as string,\n\t\tModifiedDate as timestamp\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tlimit: 1,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> DBSource\nLabelSource2 split(isNull(byName('ProductID')),\n\tdisjoint: false) ~> ConditionalSplit1@(badSchema, goodSchema)\nLabelSource split(size(columnNames()) != 6,\n\tdisjoint: false) ~> ColumnCount@(badColCount, goodColCount)\nColumnCount@goodColCount derive(MovieID = toInteger(byName('movie')),\n\t\tMovieTitle = byName('title'),\n\t\tMovieYearReleased = toInteger(byName('year')),\n\t\tMovieRating = toInteger(byName('Rating')),\n\t\tMovieGenres = split(toString(byName('genres')),'|')) ~> BuildModel\nColumnCount@badColCount, ConditionalSplit1@badSchema union(byName: true)~> GroupBadSources\nBuildModel, ConditionalSplit1@goodSchema union(byName: true)~> GroupGoodSources\nsource1 derive(sourcename = $filename,\n\t\truleName = 'Column Count') ~> LabelSource\nDBSource derive(sourcename = $dbname,\n\t\truleName = 'ID Check') ~> LabelSource2\nGroupBadSources derive(results = 'bad') ~> SetAsBad\nGroupGoodSources derive(results = 'good') ~> SetAsGood\nSetAsBad, SetAsGood union(byName: true)~> GroupAll\nGroupAll aggregate(NumGood = sumIf(results=='good', 1),\n\t\tNumBad = sumIf(results=='bad',1)) ~> CountBadGood\nGroupAll sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['metachecker.csv'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\tsourcename,\n\t\truleName,\n\t\tresults\n\t),\n\tpartitionBy('hash', 1)) ~> WriteResults\nCountBadGood sink(validateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: true,\n\tsaveOrder: 1) ~> OutputToPipeline"
		}
	}
}
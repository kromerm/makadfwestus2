{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "makadfwestus2"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/partdata')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Parquet3",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ParquetOutput",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Myprojection",
							"description": "Creates an explicit mapping for each drifted column"
						},
						{
							"name": "Filter1"
						}
					],
					"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\trowUrlColumn: 'myfilename',\n\tpartitionRootPath: 'partdata',\n\tformat: 'parquet',\n\twildcardPaths:['partdata/**/**/*.parquet']) ~> source1\nFilter1 derive(Title = reverse(Title)) ~> DerivedColumn1\nsource1 derive(MovieIdDupe = toInteger(byName('MovieIdDupe')),\n\t\tActionDupe = toString(byName('ActionDupe')),\n\t\tMovieId = toInteger(byName('MovieId')),\n\t\tTitle = toString(byName('Title')),\n\t\tGenre = toString(byName('Genre')),\n\t\tYear = toInteger(byName('Year')),\n\t\tRating = toInteger(byName('Rating')),\n\t\tRottenTom = toInteger(byName('RottenTom')),\n\t\tAction = toString(byName('Action')),\n\t\treleaseyear = toInteger(byName('releaseyear')),\n\t\tMonth = toInteger(byName('Month'))) ~> Myprojection\nMyprojection filter(releaseyear == 2019) ~> Filter1\nDerivedColumn1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\ttruncate: true,\n\tpartitionBy('key',\n\t\t0,\n\t\treleaseyear,\n\t\tMonth\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/partfiles')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "partsource",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Aggregate1"
						}
					],
					"scriptLines": [
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     rowUrlColumn: 'myfilename',",
						"     partitionRootPath: 'myfolder/partdata',",
						"     format: 'parquet',",
						"     wildcardPaths:['myfolder/partdata/**/**/*.parquet']) ~> source1",
						"source1 aggregate(groupBy(myfilename),",
						"     total = sum(1)) ~> Aggregate1",
						"Aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/partitions')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "userdata",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Parquet1Folder",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						}
					],
					"script": "source(output(\n\t\tregistration_dttm as timestamp,\n\t\tid as integer,\n\t\tfirst_name as string,\n\t\tlast_name as string,\n\t\temail as string,\n\t\tgender as string,\n\t\tip_address as string,\n\t\tcc as string,\n\t\tcountry as string,\n\t\tbirthdate as string,\n\t\tsalary as double,\n\t\ttitle as string,\n\t\tcomments as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet') ~> source1\nsource1 derive(id = 1) ~> DerivedColumn1\nDerivedColumn1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('key',\n\t\t0,\n\t\tid\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/percentOfTotal')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "loans",
								"type": "DatasetReference"
							},
							"name": "loans1"
						},
						{
							"dataset": {
								"referenceName": "loans",
								"type": "DatasetReference"
							},
							"name": "loans2"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "TotalAmount"
						},
						{
							"name": "percentTotal"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          member_id as integer,",
						"          loan_amnt as double,",
						"          funded_amnt as double,",
						"          funded_amnt_inv as double,",
						"          term as string,",
						"          int_rate as double,",
						"          installment as double,",
						"          grade as string,",
						"          sub_grade as string,",
						"          emp_title as string,",
						"          emp_length as string,",
						"          home_ownership as string,",
						"          annual_inc as double,",
						"          verification_status as string,",
						"          issue_d as string,",
						"          loan_status as string,",
						"          pymnt_plan as boolean,",
						"          url as string,",
						"          desc as string,",
						"          purpose as string,",
						"          title as string,",
						"          zip_code as string,",
						"          addr_state as string,",
						"          dti as string,",
						"          delinq_2yrs as string,",
						"          earliest_cr_line as string,",
						"          inq_last_6mths as string,",
						"          mths_since_last_delinq as string,",
						"          mths_since_last_record as double,",
						"          open_acc as string,",
						"          pub_rec as double,",
						"          revol_bal as double,",
						"          revol_util as double,",
						"          total_acc as double,",
						"          initial_list_status as string,",
						"          out_prncp as double,",
						"          out_prncp_inv as string,",
						"          total_pymnt as double,",
						"          total_pymnt_inv as string,",
						"          total_rec_prncp as double,",
						"          total_rec_int as double,",
						"          total_rec_late_fee as double,",
						"          recoveries as double,",
						"          collection_recovery_fee as double,",
						"          last_pymnt_d as string,",
						"          last_pymnt_amnt as double,",
						"          next_pymnt_d as string,",
						"          last_credit_pull_d as string,",
						"          collections_12_mths_ex_med as string,",
						"          mths_since_last_major_derog as string,",
						"          policy_code as string,",
						"          application_type as string,",
						"          annual_inc_joint as double,",
						"          dti_joint as string,",
						"          verification_status_joint as double,",
						"          acc_now_delinq as string,",
						"          tot_coll_amt as string,",
						"          tot_cur_bal as double,",
						"          open_acc_6m as string,",
						"          open_il_6m as double,",
						"          open_il_12m as string,",
						"          open_il_24m as string,",
						"          mths_since_rcnt_il as string,",
						"          total_bal_il as string,",
						"          il_util as string,",
						"          open_rv_12m as string,",
						"          open_rv_24m as string,",
						"          max_bal_bc as string,",
						"          all_util as string,",
						"          total_rev_hi_lim as string,",
						"          inq_fi as string,",
						"          total_cu_tl as string,",
						"          inq_last_12m as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> loans1",
						"source(output(",
						"          id as integer,",
						"          member_id as integer,",
						"          loan_amnt as double,",
						"          funded_amnt as double,",
						"          funded_amnt_inv as double,",
						"          term as string,",
						"          int_rate as double,",
						"          installment as double,",
						"          grade as string,",
						"          sub_grade as string,",
						"          emp_title as string,",
						"          emp_length as string,",
						"          home_ownership as string,",
						"          annual_inc as double,",
						"          verification_status as string,",
						"          issue_d as string,",
						"          loan_status as string,",
						"          pymnt_plan as boolean,",
						"          url as string,",
						"          desc as string,",
						"          purpose as string,",
						"          title as string,",
						"          zip_code as string,",
						"          addr_state as string,",
						"          dti as string,",
						"          delinq_2yrs as string,",
						"          earliest_cr_line as string,",
						"          inq_last_6mths as string,",
						"          mths_since_last_delinq as string,",
						"          mths_since_last_record as double,",
						"          open_acc as string,",
						"          pub_rec as double,",
						"          revol_bal as double,",
						"          revol_util as double,",
						"          total_acc as double,",
						"          initial_list_status as string,",
						"          out_prncp as double,",
						"          out_prncp_inv as string,",
						"          total_pymnt as double,",
						"          total_pymnt_inv as string,",
						"          total_rec_prncp as double,",
						"          total_rec_int as double,",
						"          total_rec_late_fee as double,",
						"          recoveries as double,",
						"          collection_recovery_fee as double,",
						"          last_pymnt_d as string,",
						"          last_pymnt_amnt as double,",
						"          next_pymnt_d as string,",
						"          last_credit_pull_d as string,",
						"          collections_12_mths_ex_med as string,",
						"          mths_since_last_major_derog as string,",
						"          policy_code as string,",
						"          application_type as string,",
						"          annual_inc_joint as double,",
						"          dti_joint as string,",
						"          verification_status_joint as double,",
						"          acc_now_delinq as string,",
						"          tot_coll_amt as string,",
						"          tot_cur_bal as double,",
						"          open_acc_6m as string,",
						"          open_il_6m as double,",
						"          open_il_12m as string,",
						"          open_il_24m as string,",
						"          mths_since_rcnt_il as string,",
						"          total_bal_il as string,",
						"          il_util as string,",
						"          open_rv_12m as string,",
						"          open_rv_24m as string,",
						"          max_bal_bc as string,",
						"          all_util as string,",
						"          total_rev_hi_lim as string,",
						"          inq_fi as string,",
						"          total_cu_tl as string,",
						"          inq_last_12m as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> loans2",
						"loans1 aggregate(total_amount = sum(toInteger(loan_amnt))) ~> TotalAmount",
						"loans2 derive(percent_of_total = loan_amnt / sink1#output().total_amount) ~> percentTotal",
						"TotalAmount sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: false,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/powerquery6')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "WranglingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"name": "MoviesD2",
							"script": "source(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> MoviesD2",
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							}
						}
					],
					"script": "section Section1;\r\nshared MoviesD2 = let\r\n  AdfDoc = AzureStorage.BlobContents(\"https://makadf001.blob.core.windows.net/mycontainer/SampleData/moviesDB.csv\"),\r\n  Csv = Csv.Document(AdfDoc, [Delimiter = \",\", Encoding = TextEncoding.Utf8, QuoteStyle = QuoteStyle.Csv]),\r\n  PromotedHeaders = Table.PromoteHeaders(Csv, [PromoteAllScalars = true])\r\nin\r\n  PromotedHeaders;\r\nshared UserQuery = let\r\n  Source = MoviesD2\r\nin\r\n  Source;\r\nshared #\"UserQuery (2)\" = let\r\n  Source = MoviesD2,\r\n  #\"Appended query\" = Table.Combine({Source, UserQuery})\r\nin\r\n  #\"Appended query\";\r\n",
					"documentLocale": "en-us"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/regex')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "moviesCSV",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "DerivedColumn2"
						},
						{
							"name": "SurrogateKey1"
						}
					],
					"script": "source(output(\n\t\tmovie as string,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as string,\n\t\tRating as string,\n\t\tRottenTomato as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> source1\nDerivedColumn2 derive(Location = :local1[1],\n\t\tAsset = iif(size(:local1)<3,toString(null()),:local1[2]),\n\t\tAttribute = iif(size(:local1)<3,:local1[2],:local1[3]),\n\t\tlocal1 := regexSplit(Resource,'\\\\s|_|\\\\.|-')) ~> DerivedColumn1\nSurrogateKey1 derive(Resource = iif(sk % 2 == 0,'Atlanta-CKT606.Battery',iif(sk==3,'Atlanta.Battery','Atlanta.Bus2_Volts'))) ~> DerivedColumn2\nsource1 keyGenerate(output(sk as long),\n\tstartAt: 1L,\n\tstepValue: 1L) ~> SurrogateKey1\nDerivedColumn1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: false,\n\tsaveOrder: 1) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/restdataflow')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"linkedService": {
								"referenceName": "WeatherRest",
								"type": "LinkedServiceReference"
							},
							"name": "WeatherRestSource"
						},
						{
							"dataset": {
								"referenceName": "Xml2",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "TextFileOut"
						}
					],
					"transformations": [
						{
							"name": "FlattenPeriods"
						},
						{
							"name": "CreateForecasts"
						},
						{
							"name": "CollectForecasts"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "CreateMap"
						},
						{
							"name": "derivedColumn2"
						}
					],
					"script": "source(output(\n\t\tbody as ({@context} as string[], geometry as (coordinates as double[][][], type as string), properties as (elevation as (unitCode as string, value as double), forecastGenerator as string, generatedAt as string, periods as (detailedForecast as string, endTime as string, icon as string, isDaytime as boolean, name as string, number as short, shortForecast as string, startTime as string, temperature as short, temperatureTrend as string, temperatureUnit as boolean, windDirection as string, windSpeed as string)[], units as string, updateTime as string, updated as string, validTimes as string), type as string),\n\t\theaders as [string,string]\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'rest',\n\ttimeout: 30,\n\trequestInterval: 0,\n\thttpMethod: 'GET',\n\tresponseFormat: ['type' -> 'json', 'documentForm' -> 'documentPerLine']) ~> WeatherRestSource\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tvalidationMode: 'none',\n\tnamespaces: true) ~> source1\nderivedColumn1 foldDown(unroll(body.properties.periods),\n\tmapColumn(\n\t\tforecastGenerator = body.properties.forecastGenerator,\n\t\tgeneratedAt = body.properties.generatedAt,\n\t\tdetailedForecast = body.properties.periods.detailedForecast,\n\t\tendTime = body.properties.periods.endTime,\n\t\ticon = body.properties.periods.icon,\n\t\tisDaytime = body.properties.periods.isDaytime,\n\t\tname = body.properties.periods.name,\n\t\tnumber = body.properties.periods.number,\n\t\tshortForecast = body.properties.periods.shortForecast,\n\t\tstartTime = body.properties.periods.startTime,\n\t\ttemperature = body.properties.periods.temperature,\n\t\ttemperatureTrend = body.properties.periods.temperatureTrend,\n\t\ttemperatureUnit = body.properties.periods.temperatureUnit,\n\t\twindDirection = body.properties.periods.windDirection,\n\t\twindSpeed = body.properties.periods.windSpeed,\n\t\tunits = body.properties.units,\n\t\tupdateTime = body.properties.updateTime,\n\t\tupdated = body.properties.updated,\n\t\tvalidTimes = body.properties.validTimes,\n\t\ttype = body.type\n\t),\n\tskipDuplicateMapInputs: false,\n\tskipDuplicateMapOutputs: false) ~> FlattenPeriods\nderivedColumn2 derive(forecast = @(name=name,\n\t\tshortForecast=shortForecast,\n\t\ttemperature=temperature)) ~> CreateForecasts\nCreateForecasts aggregate(forecasts = collect(forecast)) ~> CollectForecasts\nWeatherRestSource derive(column1 = slice(body.geometry.coordinates,1),\n\t\tsizeOfArray := size(body.geometry.coordinates)) ~> derivedColumn1\nFlattenPeriods derive(forecastmap = associate('When',name,'Where',generatedAt,'What',shortForecast)) ~> CreateMap\nCreateMap derive(column1 = reassociate(forecastmap, iif(#key=='Where','PA',#value))) ~> derivedColumn2\nCollectForecasts sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tpartitionBy('hash', 2,\n\t\tERROR_FUNCTION('')\n\t)) ~> TextFileOut"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/row fingerprints')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "moviesCSV",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "moviesCSV",
								"type": "DatasetReference"
							},
							"name": "source3"
						},
						{
							"dataset": {
								"referenceName": "moviesCSV",
								"type": "DatasetReference"
							},
							"name": "source4"
						}
					],
					"sinks": [
						{
							"name": "CachedSink1"
						},
						{
							"dataset": {
								"referenceName": "Json4folder",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "genHash1"
						},
						{
							"name": "SelectCols"
						},
						{
							"name": "Join1"
						},
						{
							"name": "SelectCols1"
						},
						{
							"name": "genHash"
						},
						{
							"name": "CachedLookup"
						},
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Select1"
						}
					],
					"script": "parameters{\n\tparameter1 as string[] (['movie','title','year'])\n}\nsource(output(\n\t\tmovie as string,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as string,\n\t\tRating as string,\n\t\tRottenTomato as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> source1\nsource(output(\n\t\tmovie as string,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as string,\n\t\tRating as string,\n\t\tRottenTomato as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> source3\nsource(output(\n\t\tmovie as string,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as string,\n\t\tRating as string,\n\t\tRottenTomato as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> source4\nSelectCols derive(myhash = sha2(256, columns())) ~> genHash1\nsource1 select(mapColumn(\n\t\tyear,\n\t\tRating,\n\t\tRottenTomato\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SelectCols\nCachedLookup, genHash1 join(source1@RottenTomato == SelectCols@RottenTomato\n\t&& source1@Rating == SelectCols@Rating\n\t&& source1@year == SelectCols@year,\n\tjoinType:'inner',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> Join1\nsource3 select(mapColumn(\n\t\tyear,\n\t\tRating,\n\t\tRottenTomato\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> SelectCols1\nSelectCols1 derive(myhash1 = sha2(256,columns())) ~> genHash\nsource1 derive(myhash1 = CachedSink1#lookup(year,Rating,RottenTomato)) ~> CachedLookup\nSelect1 derive(myhash2 = sha2(256, byNames($parameter1)),\n\t\tmyhash3 = sha2(256,columns())) ~> DerivedColumn1\nsource4 select(mapColumn(\n\t\tmovie,\n\t\ttitle,\n\t\tyear\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Select1\ngenHash sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tkeys:['year','Rating','RottenTomato'],\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: false,\n\tsaveOrder: 1) ~> CachedSink1\nJoin1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\t{@CustomerID} as string,\n\t\t{AW:CompanyName} as string,\n\t\t{AW:ContactName} as string,\n\t\t{AW:ContactTitle} as string,\n\t\t{AW:FullAddress} as ({AW:Address} as string, {AW:City} as string, {AW:Country} as string, {AW:PostalCode} as integer, {AW:Region} as string),\n\t\t{AW:Phone} as string,\n\t\t{AW:CustomerID} as string,\n\t\t{AW:EmployeeID} as integer,\n\t\t{AW:OrderDate} as string,\n\t\t{AW:RequiredDate} as string,\n\t\t{AW:ShipInfo} as ({@ShippedDate} as string, {AW:Freight} as double, {AW:ShipAddress} as string, {AW:ShipCity} as string, {AW:ShipCountry} as string, {AW:ShipName} as string, {AW:ShipPostalCode} as integer, {AW:ShipRegion} as string, {AW:ShipVia} as integer)\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tsaveOrder: 2) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sinkIfMoreThanNRows')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							},
							"name": "moviesSource"
						},
						{
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							},
							"name": "rowcountSource"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "Aggregate1"
						},
						{
							"name": "ConditionalSplit1"
						},
						{
							"name": "Filter1"
						}
					],
					"script": "parameters{\n\tparameter1 as integer (0)\n}\nsource(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as short,\n\t\tRating as short,\n\t\tRottenTomato as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> moviesSource\nsource(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as short,\n\t\tRating as short,\n\t\tRottenTomato as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> rowcountSource\nFilter1 aggregate(rowcount = count(1)) ~> Aggregate1\nmoviesSource split(sink1#output().rowcount > $parameter1,\n\tdisjoint: false) ~> ConditionalSplit1@(greaterThan, lessThan)\nrowcountSource filter(year == 1980) ~> Filter1\nAggregate1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: false,\n\tsaveOrder: 1) ~> sink1\nConditionalSplit1@greaterThan sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> sink2"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sqlDelete')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							},
							"name": "moviesFile"
						},
						{
							"dataset": {
								"referenceName": "SQLMovies",
								"type": "DatasetReference"
							},
							"name": "moviesDB1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SQLMovies",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "AlterRow1"
						},
						{
							"name": "Exists2"
						}
					],
					"script": "source(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as short,\n\t\tRating as short,\n\t\tRottenTomato as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> moviesFile\nsource(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as integer,\n\t\tRating as integer,\n\t\tRottenTomato as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table') ~> moviesDB1\nExists2 alterRow(deleteIf(true())) ~> AlterRow1\nmoviesDB1, moviesFile exists(moviesDB1@movie == moviesFile@movie,\n\tnegate:true,\n\tbroadcast: 'auto')~> Exists2\nAlterRow1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as integer,\n\t\tRating as integer,\n\t\tRottenTomato as integer\n\t),\n\tdeletable:true,\n\tinsertable:false,\n\tupdateable:false,\n\tupsertable:false,\n\tkeys:['movie'],\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError') ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/sqlmovies')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "SQLMovies",
								"type": "DatasetReference"
							},
							"name": "source2"
						},
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "source3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "SQLMovies",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Filter1"
						},
						{
							"name": "AlterRow1"
						},
						{
							"name": "RowCount"
						}
					],
					"script": "source(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as short,\n\t\tRating as short,\n\t\tRottenTomato as short\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tpartitionBy('external', 16)) ~> source1\nsource(output(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as integer,\n\t\tRating as integer,\n\t\tRottenTomato as integer\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tisolationLevel: 'READ_UNCOMMITTED',\n\tformat: 'table',\n\tpartitionColumn: 'movie',\n\tpartitionBy('external', 16)) ~> source2\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\twildcardPaths:['output/demoout1/movies2021.csv']) ~> source3\nAlterRow1 derive(year = 2021) ~> DerivedColumn1\nsource2 filter(year == 2021) ~> Filter1\nsource1 alterRow(updateIf(year==1980)) ~> AlterRow1\nsource3 aggregate(rowcount = count(1)) ~> RowCount\nDerivedColumn1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as integer,\n\t\tRating as integer,\n\t\tRottenTomato as integer\n\t),\n\tdeletable:false,\n\tinsertable:false,\n\tupdateable:true,\n\tupsertable:false,\n\tkeys:['movie'],\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tsaveOrder: 1,\n\terrorHandlingOption: 'stopOnFirstError') ~> sink1\nFilter1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['movies2021.csv'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tsaveOrder: 2,\n\tpartitionBy('hash', 1)) ~> sink2\nRowCount sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['movies2021rowcount.csv'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tsaveOrder: 3,\n\tpartitionBy('hash', 1)) ~> sink3"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/stringify')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "RestResource1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "folderout1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Stringify1"
						},
						{
							"name": "Select1"
						}
					],
					"script": "source(output(\n\t\tbody as ({@context} as string[], geometry as (coordinates as double[][][], type as string), properties as (elevation as (unitCode as string, value as double), forecastGenerator as string, generatedAt as string, periods as (detailedForecast as string, endTime as string, icon as string, isDaytime as boolean, name as string, number as short, shortForecast as string, startTime as string, temperature as short, temperatureTrend as string, temperatureUnit as boolean, windDirection as string, windSpeed as string)[], units as string, updateTime as string, updated as string, validTimes as string), type as string),\n\t\theaders as [string,string]\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\thttpMethod: 'GET',\n\ttimeout: 30,\n\trequestInterval: 0,\n\tresponseFormat: ['type' -> 'json', 'documentForm' -> 'documentPerLine']) ~> source1\nsource1 stringify(mydata = body.properties.periods ? string,\n\tformat: 'json') ~> Stringify1\nStringify1 select(mapColumn(\n\t\tcontext = mydata\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Select1\nSelect1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tsaveOrder: 1) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/taxiDemo')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "taxi_fare_data_input1",
								"type": "DatasetReference"
							},
							"name": "taxiSource"
						},
						{
							"dataset": {
								"referenceName": "taxi_trip_data_input1",
								"type": "DatasetReference"
							},
							"name": "tripSource"
						}
					],
					"sinks": [
						{
							"linkedService": {
								"referenceName": "AzureDataLakeStorage1",
								"type": "LinkedServiceReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Join1"
						},
						{
							"name": "Aggregate1"
						},
						{
							"name": "Sort1"
						},
						{
							"name": "Aggregate2"
						},
						{
							"name": "Sort2"
						}
					],
					"script": "source(output(\n\t\tmedallion as string,\n\t\t{ hack_license} as string,\n\t\t{ vendor_id} as string,\n\t\t{ pickup_datetime} as timestamp,\n\t\t{ payment_type} as string,\n\t\t{ fare_amount} as double,\n\t\t{ surcharge} as double,\n\t\t{ mta_tax} as double,\n\t\t{ tip_amount} as double,\n\t\t{ tolls_amount} as double,\n\t\t{ total_amount} as double\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> taxiSource\nsource(output(\n\t\tmedallion as string,\n\t\thack_license as string,\n\t\tvendor_id as string,\n\t\trate_code as short,\n\t\tstore_and_fwd_flag as boolean,\n\t\tpickup_datetime as timestamp,\n\t\tdropoff_datetime as timestamp,\n\t\tpassenger_count as short,\n\t\ttrip_time_in_secs as short,\n\t\ttrip_distance as double,\n\t\tpickup_longitude as double,\n\t\tpickup_latitude as double,\n\t\tdropoff_longitude as double,\n\t\tdropoff_latitude as double\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> tripSource\ntaxiSource, tripSource join(taxiSource@medallion == tripSource@medallion\n\t&& { hack_license} == hack_license,\n\tjoinType:'inner',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'auto')~> Join1\nJoin1 aggregate(groupBy(passenger_count),\n\tavgAmount = round(avg({ total_amount}),2),\n\t\tavgTip = round(avg({ tip_amount}),2)) ~> Aggregate1\nAggregate1 sort(desc(avgTip, true)) ~> Sort1\nJoin1 aggregate(groupBy(round_distance = round(trip_distance)),\n\tavgAmount2 = round(avg({ total_amount}),2),\n\t\tavgTip2 = round(avg({ tip_amount}),2)) ~> Aggregate2\nAggregate2 sort(desc(avgTip2, true)) ~> Sort2\nSort2 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'delta',\n\tfileSystem: 'mycontainer',\n\tfolderPath: 'deltataxi',\n\ttruncate:true,\n\tmergeSchema: false,\n\tautoCompact: false,\n\toptimizedWrite: false,\n\tvacuum: 0,\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/tpcds')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "tpcds100_storesales",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "datedim",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "folderout",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "Join1"
						},
						{
							"name": "Filter1"
						}
					],
					"script": "source(output(\n\t\tss_sold_time_sk as integer,\n\t\tss_item_sk as integer,\n\t\tss_customer_sk as integer,\n\t\tss_cdemo_sk as integer,\n\t\tss_hdemo_sk as integer,\n\t\tss_addr_sk as integer,\n\t\tss_store_sk as integer,\n\t\tss_promo_sk as integer,\n\t\tss_ticket_number as long,\n\t\tss_quantity as integer,\n\t\tss_wholesale_cost as decimal(7,2),\n\t\tss_list_price as decimal(7,2),\n\t\tss_sales_price as decimal(7,2),\n\t\tss_ext_discount_amt as decimal(7,2),\n\t\tss_ext_sales_price as decimal(7,2),\n\t\tss_ext_wholesale_cost as decimal(7,2),\n\t\tss_ext_list_price as decimal(7,2),\n\t\tss_ext_tax as decimal(7,2),\n\t\tss_coupon_amt as decimal(7,2),\n\t\tss_net_paid as decimal(7,2),\n\t\tss_net_paid_inc_tax as decimal(7,2),\n\t\tss_net_profit as decimal(7,2),\n\t\tss_sold_date_sk as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: true,\n\tpartitionRootPath: 'tpcsales',\n\tformat: 'parquet',\n\twildcardPaths:['SampleData/tpcds/tpcsales/**/*']) ~> source1\nsource(output(\n\t\td_date_sk as integer,\n\t\td_date_id as string,\n\t\td_date as date,\n\t\td_month_seq as integer,\n\t\td_week_seq as integer,\n\t\td_quarter_seq as integer,\n\t\td_year as integer,\n\t\td_dow as integer,\n\t\td_moy as integer,\n\t\td_dom as integer,\n\t\td_qoy as integer,\n\t\td_fy_year as integer,\n\t\td_fy_quarter_seq as integer,\n\t\td_fy_week_seq as integer,\n\t\td_day_name as string,\n\t\td_quarter_name as string,\n\t\td_holiday as string,\n\t\td_weekend as string,\n\t\td_following_holiday as string,\n\t\td_first_dom as integer,\n\t\td_last_dom as integer,\n\t\td_same_day_ly as integer,\n\t\td_same_day_lq as integer,\n\t\td_current_day as string,\n\t\td_current_week as string,\n\t\td_current_month as string,\n\t\td_current_quarter as string,\n\t\td_current_year as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tformat: 'parquet') ~> source2\nsource1, source2 join(ss_sold_time_sk == d_date_sk,\n\tjoinType:'inner',\n\tmatchType:'exact',\n\tignoreSpaces: false,\n\tbroadcast: 'right')~> Join1\nJoin1 filter(d_year == 2002) ~> Filter1\nFilter1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tmapColumn(\n\t\tSSDate = ss_sold_time_sk,\n\t\tDDate = d_date_sk,\n\t\t{DYear } = d_year\n\t)) ~> sink1"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/updateMovieParts')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "MoviesD2",
								"type": "DatasetReference"
							},
							"name": "movies"
						},
						{
							"dataset": {
								"referenceName": "taxi_trip_data_input1",
								"type": "DatasetReference"
							},
							"name": "taxiSource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ParquetPartMovies",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "ParquetPart",
								"type": "DatasetReference"
							},
							"name": "taxiSink"
						}
					],
					"transformations": [
						{
							"name": "DerivedColumn1"
						},
						{
							"name": "Filter1"
						},
						{
							"name": "Select1"
						},
						{
							"name": "decompdatetime"
						}
					],
					"script": "source(output(\n\t\tmovie as string,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as string,\n\t\tRating as string,\n\t\tRottenTomato as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> movies\nsource(output(\n\t\tmedallion as string,\n\t\thack_license as string,\n\t\tvendor_id as string,\n\t\trate_code as string,\n\t\tstore_and_fwd_flag as string,\n\t\tpickup_datetime as string,\n\t\tdropoff_datetime as string,\n\t\tpassenger_count as string,\n\t\ttrip_time_in_secs as string,\n\t\ttrip_distance as string,\n\t\tpickup_longitude as string,\n\t\tpickup_latitude as string,\n\t\tdropoff_longitude as string,\n\t\tdropoff_latitude as string\n\t),\n\tallowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false) ~> taxiSource\nFilter1 derive(movie = '999979',\n\t\ttitle = 'Mark Story') ~> DerivedColumn1\nmovies filter(title == 'Toy Story') ~> Filter1\nDerivedColumn1 select(mapColumn(\n\t\tmovie,\n\t\ttitle,\n\t\tgenres,\n\t\tyear,\n\t\tRating,\n\t\tRottenTomato\n\t),\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true) ~> Select1\ntaxiSource derive(month = split(pickup_datetime,'-')[2],\n\t\tyear = toInteger(split(pickup_datetime,'-')[1])+1,\n\t\tday = split(split(pickup_datetime,' ')[1],'-')[3]) ~> decompdatetime\nSelect1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tumask: 0022,\n\tpreCommands: [],\n\tpostCommands: [],\n\tpartitionBy('key',\n\t\t0,\n\t\tyear\n\t)) ~> sink1\ndecompdatetime sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tformat: 'parquet',\n\tpartitionBy('key',\n\t\t0,\n\t\tyear,\n\t\tmonth,\n\t\tday\n\t)) ~> taxiSink"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CDC Storage')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "CDC ADLS Gen2 Test",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "1.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "CDC ADLS Gen2",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								},
								"linkedServiceParameters": {}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "dataflowIRwReuse",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine",
							"continuationSettings": {
								"customizedCheckpointKey": "83b74f57-3df1-4439-8686-5379c1101614"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/CopyPipelineForDemo')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Copy_n1y",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [
							{
								"name": "Source",
								"value": "mycontainer/SampleData/moviesDB.csv"
							},
							{
								"name": "Destination",
								"value": ".DTPDemo1"
							}
						],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": false,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings",
									"skipLineCount": 0
								}
							},
							"sink": {
								"type": "AzureSqlSink",
								"writeBehavior": "insert",
								"tableOption": "autoCreate"
							},
							"enableStaging": false,
							"validateDataConsistency": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "movie",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "movie",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "title",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "title",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "genres",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "genres",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "year",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "year",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "Rating",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "Rating",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "RottenTomato",
											"type": "String",
											"physicalType": "String"
										},
										"sink": {
											"name": "RottenTomato",
											"type": "String"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "SourceDataset_n1y",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DestinationDataset_n1y",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DQPipe2')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DQ Rules",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DataQuality1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"loansSource": {},
									"rules1": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"parameters": {
					"rootfolder": {
						"type": "string",
						"defaultValue": "'rootfolder'"
					},
					"cdmfolder": {
						"type": "string",
						"defaultValue": "'cdmfolder'"
					}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/Data Cleansing')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Clean Names and Values",
						"type": "ExecuteWranglingDataflow",
						"dependsOn": [
							{
								"activity": "Ingest to Lake",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "moviesWrangling",
								"type": "DataFlowReference",
								"datasetParameters": {
									"moviesCSV": {},
									"SQLMovies": {},
									"SinkSQLMovies": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "dataflowIRwReuse",
								"type": "IntegrationRuntimeReference"
							},
							"queries": [
								{
									"queryName": "UserQuery",
									"dataflowSinks": [
										{
											"name": "SinkSQLMovies",
											"dataset": {
												"referenceName": "SQLMovies",
												"type": "DatasetReference",
												"parameters": {}
											},
											"script": "sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tinput(\n\t\tmovie as integer,\n\t\ttitle as string,\n\t\tgenres as string,\n\t\tyear as integer,\n\t\tRating as integer,\n\t\tRottenTomato as integer\n\t),\n\tdeletable:false,\n\tinsertable:true,\n\tupdateable:false,\n\tupsertable:false,\n\tformat: 'table',\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\terrorHandlingOption: 'stopOnFirstError',\n\tmapColumn(\n\t\tmovie,\n\t\ttitle,\n\t\tgenres,\n\t\tyear,\n\t\tRating\n\t)) ~> SinkSQLMovies"
										}
									]
								}
							]
						}
					},
					{
						"name": "Ingest to Lake",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobStorageWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".txt"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "moviesCSV",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "folderout",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Dedupe",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Clean Names and Values",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataDedupe",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"sourceName": {},
									"sinkDupes": {},
									"sinkNoDupes": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "dataflowIRwReuse",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Send Email",
						"type": "WebActivity",
						"dependsOn": [
							{
								"activity": "Dedupe",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"url": "http://www.yahoo.com",
							"method": "GET",
							"headers": {}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DeltaPipeline')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "DeltaUpdates",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "DeltaLake1",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		}
	]
}